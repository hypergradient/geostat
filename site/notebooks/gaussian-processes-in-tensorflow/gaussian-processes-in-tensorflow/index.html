<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../../img/favicon.ico">
        <title>Gaussian processes in Tensorflow - Geostat Documentation</title>
        <link href="../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../css/fontawesome.min.css" rel="stylesheet">
        <link href="../../../css/brands.min.css" rel="stylesheet">
        <link href="../../../css/solid.min.css" rel="stylesheet">
        <link href="../../../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../../../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <link href="../../../assets/_mkdocstrings.css" rel="stylesheet">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../../..">Geostat Documentation</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="nav-item">
                                <a href="../../.." class="nav-link">Home</a>
                            </li>
                            <li class="nav-item">
                                <a href="../../../api/" class="nav-link">API Reference</a>
                            </li>
                            <li class="nav-item">
                                <a href="../../../examples/" class="nav-link">Examples</a>
                            </li>
                            <li class="nav-item">
                                <a href="../../../about/" class="nav-link">About</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="1"><a href="#gaussian-processes-in-tensorflow" class="nav-link">Gaussian processes in Tensorflow</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="gaussian-processes-in-tensorflow">Gaussian processes in Tensorflow</h1>
<pre><code class="language-python">import tensorflow as tf
tf.__version__
</code></pre>
<pre><code>'1.8.0'
</code></pre>
<p>Geostatistical datasets are often a set of measurements with locations. Nearby measurements covary a lot. Distant measurements are nearly independent.</p>
<p>Let's simulate this:</p>
<ul>
<li>Define <span class="arithmatex">\(N\)</span> locations <span class="arithmatex">\(x\)</span> by drawing uniformly at random from a square area.</li>
<li>Create <span class="arithmatex">\(N\times N\)</span> distance matrix <span class="arithmatex">\(D\)</span> (euclidean distance between locations).</li>
<li>Define a covariance function: <span class="arithmatex">\(c(d; r, s, n) = s \cdot \exp(-(d/r)^2) + n \cdot \delta_d\)</span>, where <span class="arithmatex">\(d\)</span> is distance, and <span class="arithmatex">\((r, s, n)\)</span> correspond to range/sill/nugget on a variogram. (I think the convention varies between  calling either <span class="arithmatex">\(s+n\)</span> or <span class="arithmatex">\(s\)</span> the sill.) Also, <span class="arithmatex">\(\delta_d\)</span> is 1 when <span class="arithmatex">\(d\)</span> is 0, and 0 otherwise.</li>
<li>Use the covariance function to map <span class="arithmatex">\(D\)</span> elementwise to a covariance matrix <span class="arithmatex">\(C\)</span>.</li>
<li>Draw <span class="arithmatex">\(u \sim \textrm{Normal}(\beta_1 \cdot \mathbb{1}, C)\)</span> to obtain values, where <span class="arithmatex">\(\beta_1\)</span> is the (scalar) mean value of a single draw, and <span class="arithmatex">\(\mathbb{1}\)</span> is a vector of <span class="arithmatex">\(N\)</span> ones.</li>
</ul>
<p>This is implemented as <code>simulate_gp</code> below. The range is called <code>vrange</code> to avoid conflicting with Python's <code>range</code>.</p>
<p>The data consists of locations <code>x</code> (or equivalently, the distance matrix <code>D</code>) and measurements <code>u</code>.</p>
<pre><code class="language-python">import numpy as np
from scipy.spatial.distance import cdist
np.set_printoptions(precision=2, threshold=50)

def simulate_gp(N, vrange, sill, nugget, offset):

    # Sample N locations from square with corners at [±10, ±10].
    x = np.random.uniform(-10.0, 10.0, [N, 2]) 

    # Compute distance matrix for sampled locations.
    D = cdist(x, x)

    # Compute corresponding covariance matrix.
    C = sill * np.exp(-np.square(D/vrange)) + nugget * np.eye(N)

    # The mean is just a vector where every entry is the offset.
    m = np.zeros([N]) + offset

    # Simulate geospatial measurements by sampling using covariance matrix
    u = np.random.multivariate_normal(m, C)

    return x, D, C, m, u
</code></pre>
<p>Now we call <code>simulate_gp</code> and plot the result. (You may have to run this twice to get the plot to show up.)</p>
<pre><code class="language-python">x, D, C, m, u = simulate_gp(
    N = 300,
    vrange = 5.0,
    sill = 2.0,
    nugget = 2.0,
    offset = 1.0)

print(&quot;Locations&quot;)
print(x)

print(&quot;Distance matrix&quot;)
print(D)

print(&quot;Covariance matrix&quot;)
print(C)

print(&quot;Simulated measurements&quot;)
print(u)

import matplotlib.pyplot as pp

pp.scatter(x[:, 0], x[:, 1], c=u)
pp.show()
</code></pre>
<pre><code>Locations
[[ 0.83  9.5 ]
 [-6.51  0.99]
 [ 2.84  6.14]
 ...
 [-4.99  0.45]
 [-3.49  2.24]
 [ 5.49 -0.34]]
Distance matrix
[[ 0.   11.24  3.92 ... 10.76  8.45 10.89]
 [11.24  0.   10.68 ...  1.61  3.26 12.07]
 [ 3.92 10.68  0.   ...  9.68  7.44  7.  ]
 ...
 [10.76  1.61  9.68 ...  0.    2.33 10.51]
 [ 8.45  3.26  7.44 ...  2.33  0.    9.34]
 [10.89 12.07  7.   ... 10.51  9.34  0.  ]]
Covariance matrix
[[4.   0.01 1.08 ... 0.02 0.11 0.02]
 [0.01 4.   0.02 ... 1.8  1.31 0.01]
 [1.08 0.02 4.   ... 0.05 0.22 0.28]
 ...
 [0.02 1.8  0.05 ... 4.   1.61 0.02]
 [0.11 1.31 0.22 ... 1.61 4.   0.06]
 [0.02 0.01 0.28 ... 0.02 0.06 4.  ]]
Simulated measurements
[ 2.78 -0.64 -0.56 ... -0.27  2.02  2.  ]
</code></pre>
<p><img alt="png" src="../output_5_1.png" /></p>
<p>Now we make a function <code>infer_gp</code> to infer the gaussian process parameters (range, sill, nugget, offset) using maximum likelihood. We implement the same graph in Tensorflow as we did in NumPy, and tack on the negative log PDF of a multivariate normal distribution at the end, which we minimize. That is, we minimize:
<span class="arithmatex">\(<span class="arithmatex">\(-\log p(u \mid m, C) = \frac{1}{2}\bigg[\log\,\big|\, 2\pi C\,\big| + (u-m)^T C^{-1} (u-m) \bigg],\)</span>\)</span>
where <span class="arithmatex">\(m = \beta_1 \cdot \mathbb{1}\)</span>.</p>
<p>The function has two arguments:
  * <code>inputs</code> is a list of <code>numpy</code> arrays:
      * Distance matrix <code>D</code> (shape: [N, N])
      * Measurements <code>u</code> (shape: [N])
  *  <code>parameters</code> is a list of tensors for range, sill, nugget, and offset. Each tensor can be a <code>tf.Variables</code> (if it is to be inferred) or a constant (if it's a given).</p>
<pre><code class="language-python">def infer_gp(inputs, parameters):

    D, u = inputs
    vrange, sill, nugget, offset = parameters

    # Construct covariance; boost diagonal by 1e-6 for numerical stability.
    covariance = sill * tf.exp(-tf.square(tf.constant(D)/vrange)) \
               + (nugget + 1e-6) * tf.eye(D.shape[0], dtype=tf.float64)

    # Log likelihood is the PDF of a multivariate gaussian.
    u_adj = tf.constant(u) - offset
    logdet = tf.linalg.logdet(2 * np.pi * covariance)
    quad = tf.matmul(tf.expand_dims(u_adj, 0), tf.matrix_solve(covariance, tf.expand_dims(u_adj, -1)))[0, 0]
    ll = -0.5 * (logdet + quad)

    # Infer using an adaptive gradient descent optimizer.
    train = tf.train.AdamOptimizer(1e-2).minimize(-ll)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for i in range(20):
            for j in range(100):
                sess.run(train)
            print('[ll %7.2f] [range %4.2f] [sill %4.2f] [nugget %4.2f] [offset %4.2f]' % 
                  tuple(sess.run([ll, vrange, sill, nugget, offset])))

        return sess.run([vrange, sill, nugget, offset])
</code></pre>
<p>Here we make a <code>tf.Variable</code> for each parameter, using a log as the underlying representation if the parameter is positive-only.</p>
<pre><code class="language-python"># Define parameters using tf.Variable.
log_vrange = tf.Variable(0.0, dtype=tf.float64)
log_sill = tf.Variable(0.0, dtype=tf.float64)
log_nugget = tf.Variable(0.0, dtype=tf.float64)

vrange = tf.exp(log_vrange)
sill = tf.exp(log_sill)
nugget = tf.exp(log_nugget)
offset = tf.Variable(0.0, dtype=tf.float64)

vrange_val, sill_val, nugget_val, offset_val = infer_gp([D, u], [vrange, sill, nugget, offset])
</code></pre>
<pre><code>[ll -552.48] [range 2.25] [sill 1.48] [nugget 1.66] [offset 0.63]
[ll -537.88] [range 3.71] [sill 1.36] [nugget 1.68] [offset 0.84]
[ll -536.83] [range 4.20] [sill 1.38] [nugget 1.70] [offset 0.96]
[ll -536.62] [range 4.28] [sill 1.42] [nugget 1.71] [offset 1.05]
[ll -536.51] [range 4.28] [sill 1.43] [nugget 1.71] [offset 1.12]
[ll -536.45] [range 4.27] [sill 1.42] [nugget 1.71] [offset 1.18]
[ll -536.42] [range 4.26] [sill 1.41] [nugget 1.71] [offset 1.23]
[ll -536.41] [range 4.25] [sill 1.40] [nugget 1.71] [offset 1.26]
[ll -536.40] [range 4.25] [sill 1.40] [nugget 1.71] [offset 1.27]
[ll -536.40] [range 4.24] [sill 1.40] [nugget 1.71] [offset 1.29]
[ll -536.40] [range 4.24] [sill 1.40] [nugget 1.71] [offset 1.29]
[ll -536.40] [range 4.24] [sill 1.40] [nugget 1.71] [offset 1.30]
[ll -536.40] [range 4.24] [sill 1.40] [nugget 1.71] [offset 1.30]
[ll -536.40] [range 4.24] [sill 1.40] [nugget 1.71] [offset 1.30]
[ll -536.40] [range 4.24] [sill 1.40] [nugget 1.71] [offset 1.30]
[ll -536.40] [range 4.24] [sill 1.40] [nugget 1.71] [offset 1.30]
[ll -536.40] [range 4.24] [sill 1.40] [nugget 1.71] [offset 1.30]
[ll -536.40] [range 4.24] [sill 1.40] [nugget 1.71] [offset 1.30]
[ll -536.40] [range 4.24] [sill 1.40] [nugget 1.71] [offset 1.30]
[ll -536.40] [range 4.24] [sill 1.40] [nugget 1.71] [offset 1.30]
</code></pre>
<p>We can do better inference by integrating over all possibilities for <span class="arithmatex">\(\beta_1\)</span>.  (Integrating over range, sill, and nugget, which are parameters in <span class="arithmatex">\(C\)</span>, is hard; but integrating over parameters in <span class="arithmatex">\(m\)</span> is relatively easy.) This corresponds to the following generative model.</p>
<p>First, draw <span class="arithmatex">\(\beta_1\)</span> from a normal distribution:</p>
<div class="arithmatex">\[\beta_1 \sim \mathcal{N}(0, 100).\]</div>
<p>The variance should be large enough that the distribution assigns reasonably large probabilities to any plausible value for <span class="arithmatex">\(\beta_1\)</span>.</p>
<p>Next, draw <span class="arithmatex">\(u\)</span> from a multivariate normal distribution, as we've been doing all along:</p>
<div class="arithmatex">\[u \mid \beta_1 \sim \mathcal{N}(\beta_1 \cdot \mathbb{1}, C).\]</div>
<p>From this we can derive a distribution for <span class="arithmatex">\(u\)</span> by marginalizing (integrating) over <span class="arithmatex">\(\beta_1\)</span>. That is, we can compute:</p>
<div class="arithmatex">\[p(u) = \int_{-\infty}^{\infty} p(u\mid\beta_1) \, p(\beta_1) \, d\beta_1.\]</div>
<p>We rely on the abstract fact that if <span class="arithmatex">\(X_1 \sim \mathcal{N}(\mu_1, \Sigma_1)\)</span> and <span class="arithmatex">\(X_2 \mid X_1 \sim \mathcal{N}(\mu_2, \Sigma_2)\)</span>, then <span class="arithmatex">\(X_2 \sim \mathcal{N}(\mu_1, \Sigma_1 + \Sigma_2)\)</span>.  (<span class="arithmatex">\(X_1\)</span> and <span class="arithmatex">\(X_2\)</span> are vectors equal in length.) To apply this, we note that since <span class="arithmatex">\(\beta_1 \sim \mathcal{N}(0, 100)\)</span>, then <span class="arithmatex">\(\beta_1 \cdot \mathbb{1} \sim \mathcal{N}(0, 100 \cdot \mathbb{1}\mathbb{1}^T)\)</span>, where <span class="arithmatex">\(\mathbb{1}\mathbb{1}^T\)</span> is a matrix of all ones. From this it follows that</p>
<div class="arithmatex">\[u \sim \mathcal{N}(0, A)\]</div>
<p>where <span class="arithmatex">\(A = 100 \cdot \mathbb{1}\mathbb{1}^T + C.\)</span> The function below implements inference with this model, where the offset is marginalized out.</p>
<pre><code class="language-python">def infer_gp_marginalize_over_offset(inputs, parameters, offset_prior):

    D, u = inputs
    vrange, sill, nugget = parameters

    # Construct covariance; boost diagonal by 1e-6 for numerical stability.
    covariance = sill * tf.exp(-tf.square(tf.constant(D)/vrange)) \
               + (nugget + 1e-6) * tf.eye(D.shape[0], dtype=tf.float64) \
               + offset_prior

    # Log likelihood is the PDF of a multivariate gaussian.
    u_adj = tf.constant(u) - offset
    logdet = tf.linalg.logdet(2 * np.pi * covariance)
    quad = tf.matmul(tf.expand_dims(u_adj, 0), tf.matrix_solve(covariance, tf.expand_dims(u_adj, -1)))[0, 0]
    ll = -0.5 * (logdet + quad)

    # Infer using an adaptive gradient descent optimizer.
    train = tf.train.AdamOptimizer(1e-2).minimize(-ll)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for i in range(20):
            for j in range(100):
                sess.run(train)
            print('[ll %7.2f] [range %4.2f] [sill %4.2f] [nugget %4.2f]' % tuple(sess.run([ll, vrange, sill, nugget])))

        return sess.run([vrange, sill, nugget])
</code></pre>
<p>When we run this, we don't get an estimate for the offset, but the other estimates are often improved. Bear in mind that we can actually solve for the posterior distribution of the offset if we want to.</p>
<pre><code class="language-python"># Define parameters using tf.Variable.
log_vrange = tf.Variable(0.0, dtype=tf.float64)
log_sill = tf.Variable(0.0, dtype=tf.float64)
log_nugget = tf.Variable(0.0, dtype=tf.float64)

vrange = tf.exp(log_vrange)
sill = tf.exp(log_sill)
nugget = tf.exp(log_nugget)

offset_prior = 100.0

vrange_val, sill_val, nugget_val = infer_gp_marginalize_over_offset([D, u], [vrange, sill, nugget], offset_prior)
</code></pre>
<pre><code>[ll -541.34] [range 3.02] [sill 0.96] [nugget 1.69]
[ll -537.97] [range 4.51] [sill 1.13] [nugget 1.73]
[ll -537.93] [range 4.65] [sill 1.25] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
[ll -537.93] [range 4.67] [sill 1.27] [nugget 1.73]
</code></pre>
<p>Interpolation takes values at <span class="arithmatex">\(N_1\)</span> locations, and gives means and variances for <span class="arithmatex">\(N_2\)</span> locations. Formally, interpolation takes</p>
<ul>
<li>input locations <span class="arithmatex">\(x_1\)</span>, an <span class="arithmatex">\(N_1 \times 2\)</span> matrix,</li>
<li>input values <span class="arithmatex">\(u_1\)</span>, a vector of <span class="arithmatex">\(N_1\)</span> elements,</li>
<li>output locations <span class="arithmatex">\(x_2\)</span>, an <span class="arithmatex">\(N_2 \times 2\)</span> matrix.</li>
</ul>
<p>and gives a distribution for output values <span class="arithmatex">\(u_2\)</span>, a vector of <span class="arithmatex">\(N_2\)</span> elements. For notational convenience, define</p>
<div class="arithmatex">\[x = \begin{bmatrix}x_1\\x_2\end{bmatrix} \textrm{ and } u = \begin{bmatrix}u_1\\u_2\end{bmatrix}.\]</div>
<p>The model remains the same as before, so <span class="arithmatex">\(u \sim \mathcal{N}(0, A)\)</span>, where <span class="arithmatex">\(A\)</span> is constructed from a distance matrix of all locations <span class="arithmatex">\(x\)</span> as before. For clarity, let's expand <span class="arithmatex">\(u\)</span> and <span class="arithmatex">\(A\)</span>:</p>
<div class="arithmatex">\[\begin{bmatrix}u_1\\u_2\end{bmatrix} \sim \mathcal{N}\bigg(0, \begin{bmatrix}A_{11} &amp; A_{12}\\A_{21} &amp; A_{22}\end{bmatrix}\bigg).\]</div>
<p>Interpolation consists of getting a distribution for <span class="arithmatex">\(u_2\)</span> given <span class="arithmatex">\(u_1\)</span>. This is a textbook thing to do with a multivariate normal distribution, and the solution is:</p>
<div class="arithmatex">\[u_2 \mid u_1 \sim \mathcal{N}(A_{21}A_{11}^{-1}u_1,\ A_{22} - A_{21}A_{11}^{-1}A_{12}).\]</div>
<p>Bear in mind, if we just want  the marginal variance of each element in <span class="arithmatex">\(u_2\)</span>, we only need to compute the diagonal entries of <span class="arithmatex">\(A_{22} - A_{21}A_{11}^{-1}A_{12}\)</span>.</p>
<p>Refer to <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Conditional_distributions">Wikipedia</a> for more details.</p>
<pre><code class="language-python">def interpolate_gp(x1, u1, x2, parameter_vals, offset_prior):

    vrange, sill, nugget = parameter_vals

    # Compute distance matrices for sampled locations.
    D11 = cdist(x1, x1)
    D12 = cdist(x1, x2)
    D21 = cdist(x2, x1)
    D22 = cdist(x2, x2)

    # Compute covariance matrices.
    C11 = sill * np.exp(-np.square(D11/vrange)) + nugget * np.eye(len(x1)) + offset_prior
    C12 = sill * np.exp(-np.square(D12/vrange)) + offset_prior # No nugget for off-diagonal entries
    C21 = sill * np.exp(-np.square(D21/vrange)) + offset_prior # No nugget for off-diagonal entries
    C22 = sill * np.exp(-np.square(D22/vrange)) + nugget * np.eye(len(x2)) + offset_prior

    u2_mean = np.matmul(C21, np.linalg.solve(C11, u))
    u2_var = np.diag(C22) -  np.sum(C12 * np.linalg.solve(C11, C12), axis=0)

    return u2_mean, u2_var

MX = 61
MY = 61
M = MX * MY # Number of points to infer.

# Gross code to get mesh locations.
xx, yy = np.meshgrid(np.linspace(-12, 12, MX), np.linspace(-12, 12, MY))
x2 = np.hstack([xx.reshape((M, 1)), yy.reshape((M, 1))])

# Interpolate!
u2_mean, u2_var = interpolate_gp(x, u, x2, [vrange_val, sill_val, nugget_val], offset_prior)                                                                

# Plot old values, new value means, new value variances
for locations, values in [(x, u), (x2, u2_mean), (x2, u2_var)]:
    pp.scatter(locations[:, 0], locations[:, 1], c=values)
    pp.xlim(-12, 12)
    pp.ylim(-12, 12)
    pp.show()
</code></pre>
<p><img alt="png" src="../output_15_0.png" /></p>
<p><img alt="png" src="../output_15_1.png" /></p>
<p><img alt="png" src="../output_15_2.png" /></p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../../../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../js/base.js"></script>
        <script src="../../../javascripts/mathjax.js"></script>
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="../../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
